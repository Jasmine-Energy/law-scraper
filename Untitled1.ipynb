{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6552181b-07e4-43b6-a562-461ee92dffa6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Dict\n",
    "\n",
    "import torch\n",
    "import numpy as np\n",
    "import glob\n",
    "import pandas as pd\n",
    "\n",
    "from os import path\n",
    "from transformers import AutoModel, AutoTokenizer\n",
    "from sentence_transformers.util import cos_sim\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "8b442911-081f-4482-b921-36164a3e7ac9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_string(input_string, chunk_size=1800):\n",
    "    return [input_string[i:i + chunk_size] for i in range(0, len(input_string), chunk_size)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "4e79511b-9b52-4814-8d4c-e2a54f69422d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_texts():\n",
    "\n",
    "    texts, metadatas, results, file_names = [], [], [], []\n",
    "    for file_path in glob.glob('data/*.txt'):\n",
    "\n",
    "        file_name, _ = path.splitext(path.basename(file_path))\n",
    "        data = dict(param.split('=') for param in file_name.split('&'))\n",
    "\n",
    "        with open(file_path) as file:\n",
    "            text = file.read()\n",
    "            for splitted in split_string(text):\n",
    "                data['text'] = splitted\n",
    "                file_names.append(file_name)\n",
    "                results.append(data)\n",
    "\n",
    "    return file_names, results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f193c1f1-fab3-478f-8a0e-0f11a6d1a21a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "dc710b09-364d-4412-8b92-16daf98e8239",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_names, results = read_texts()\n",
    "df = pd.DataFrame.from_records(results, index=file_names)\n",
    "\n",
    "\n",
    "# For retrieval you need to pass this prompt. Please find our more in our blog post.\n",
    "def transform_query(query: str) -> str:\n",
    "    \"\"\" For retrieval, add the prompt for query (not for documents).\n",
    "    \"\"\"\n",
    "    return f'Represent this sentence for searching relevant passages: {query}'\n",
    "\n",
    "\n",
    "# The model works really well with cls pooling (default) but also with mean pooling.\n",
    "def pooling(outputs: torch.Tensor, inputs: Dict,  strategy: str = 'cls') -> np.ndarray:\n",
    "    if strategy == 'cls':\n",
    "        outputs = outputs[:, 0]\n",
    "    elif strategy == 'mean':\n",
    "        outputs = torch.sum(\n",
    "            outputs * inputs[\"attention_mask\"][:, :, None], dim=1) / torch.sum(inputs[\"attention_mask\"])\n",
    "    else:\n",
    "        raise NotImplementedError\n",
    "    return outputs.detach().cpu().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "01a725ad-cbf0-4936-8288-14b2033520c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "query = 'What are the incentives for installing solar on residential buildings? Single family homeowner in Santa Clara county with single filer'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33a5b2ba-d89b-4b41-85b2-2b67db29c15a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. load model\n",
    "model_id = 'mixedbread-ai/mxbai-embed-large-v1'\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_id)\n",
    "model = AutoModel.from_pretrained(model_id)\n",
    "\n",
    "docs = [f'Represent this sentence for searching relevant passages: {query}'] + df['text'][:500].to_list()\n",
    "\n",
    "\n",
    "# 2. encode\n",
    "inputs = tokenizer(docs, padding=True, return_tensors='pt')\n",
    "for k, v in inputs.items():\n",
    "    inputs[k] = v\n",
    "outputs = model(**inputs).last_hidden_state\n",
    "embeddings = pooling(outputs, inputs, 'cls')\n",
    "#df['embeddings'] = embeddings\n",
    "\n",
    "similarities = cos_sim(embeddings[0], embeddings[1:])\n",
    "#print('similarities:', similarities)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "7d3cde31-0137-482f-b52f-200e6120422e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.4787, 0.4787, 0.4787, 0.4787, 0.4787, 0.4787, 0.4787, 0.4787, 0.4787,\n",
       "         0.3461]])"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "similarities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f0ce9aa-7288-469b-9795-2ac8ac751c32",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a48d68c-831f-4d6d-b51a-f71c1431eaf1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
